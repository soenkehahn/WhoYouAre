{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import numpy\n",
    "from collections import deque, Counter\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from numpy import concatenate, array, asarray\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Input\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import pyaudio\n",
    "import aubio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backspace(n):\n",
    "    # print((b'\\x08').decode(), end='')\n",
    "    print('\\r', end='') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_place(string):\n",
    "    s = str(string)                       \n",
    "    print(s, end='')                        \n",
    "    sys.stdout.flush()                    \n",
    "    backspace(len(s) +1)  \n",
    "    time.sleep(0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamToFrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamToFrequency:\n",
    "    def __init__(self):\n",
    "        self.pDetection = aubio.pitch(\"yinfft\", 2048, 2048, 44100)\n",
    "        self.pDetection.set_unit(\"midi\")\n",
    "        self.pDetection.set_silence(-40)\n",
    "        self.pDetection.set_tolerance(.99)\n",
    "\n",
    "        self.output_file = open('Detection/output.txt', 'w')\n",
    "\n",
    "        self.volume_threshold = 400\n",
    "        self.acceptable_confidence = 0.61\n",
    "\n",
    "        self.past_freq = 0\n",
    "        self.predicted_frequency = 0\n",
    "\n",
    "    def callback(self, in_data, frame_count, time_info, status):\n",
    "        samples = numpy.fromstring(in_data,\n",
    "                                   dtype=aubio.float_type)\n",
    "\n",
    "        prediction = self.pDetection(samples)[0]\n",
    "\n",
    "        volume = numpy.sum(samples ** 2) / len(samples)\n",
    "        volume = round(volume, 6) * 10 ** 5\n",
    "\n",
    "        confidence = self.pDetection.get_confidence()\n",
    "\n",
    "        if confidence < self.acceptable_confidence or volume < self.volume_threshold:\n",
    "            self.predicted_frequency = 0\n",
    "        else:\n",
    "            self.predicted_frequency = prediction\n",
    "\n",
    "        prediction = round(self.predicted_frequency)\n",
    "        self.past_freq = prediction\n",
    "        return in_data, pyaudio.paContinue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.subdivision = 100/44100\n",
    "        self.isZero = True\n",
    "        self.sample_counter = 0\n",
    "        self.note_counter = 1\n",
    "        self.last_value = 0\n",
    "        self.detector = StreamToFrequency()\n",
    "        self.pred_set = deque(maxlen=9)\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=pyaudio.paFloat32,\n",
    "                                  channels=1,\n",
    "                                  rate=44100,\n",
    "                                  frames_per_buffer=2048,\n",
    "                                  input=True,\n",
    "                                  output=False,\n",
    "                                  stream_callback=self.detector.callback)\n",
    "\n",
    "    def generate_set(self):\n",
    "        while True:\n",
    "            pred = self.detector.predicted_frequency\n",
    "            value = int(round(pred))\n",
    "            # self.pred_set.append(value)\n",
    "            self.play_value(value)\n",
    "\n",
    "    def play_midi(self, value):\n",
    "        if value == 0:\n",
    "            time.sleep(.00001)\n",
    "        else:\n",
    "            sendMidi(value, .00001)\n",
    "        # sendMidi(value - 7, .01)\n",
    "        # sendMidi(value * 1.5, .001)\n",
    "\n",
    "\n",
    "    def play_silence(self):\n",
    "        print(0)\n",
    "        # time.sleep(self.subdivision * 1.0)\n",
    "\n",
    "    def restart_line(self):\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def play_value(self, value):\n",
    "        print_in_place(str(value))\n",
    "        \n",
    "        with open(\"predOutput.txt\", 'a') as myfile:\n",
    "            if value == self.last_value:\n",
    "                self.note_counter += 1\n",
    "            else:\n",
    "                stored_value = str(self.last_value)\n",
    "                if self.note_counter < 3000 or self.last_value > 100:\n",
    "                    stored_value = str(0)\n",
    "                print(self.last_value, self.note_counter)\n",
    "                # self.play_midi(self.last_value)\n",
    "                myfile.write(stored_value + ',' + str(self.note_counter) + '\\n')\n",
    "                self.note_counter = 1\n",
    "\n",
    "                # print(value == self.last_value)\n",
    "\n",
    "            self.last_value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert series to supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and Scale the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 10\n",
    "n_features = 2\n",
    "n_obs = n_hours * n_features\n",
    "# normalize features\n",
    "scaler = joblib.load('scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_array_for_prediction(testx):\n",
    "    testx = DataFrame(data = testx)\n",
    "    testx = testx.values\n",
    "    testx = testx.astype('float32')\n",
    "    testx = scaler.transform(testx)\n",
    "    testx = series_to_supervised(testx, n_hours, 1)\n",
    "    testx = testx.values\n",
    "    testx = testx[:, :n_obs]\n",
    "    testx = testx.reshape((testx.shape[0], n_hours, n_features))\n",
    "    return testx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testx = [[60, 25456],\n",
    "[59, 14880],\n",
    "[62, 25820],\n",
    "[60, 21361],\n",
    "[59, 21153],\n",
    "[60, 26320],\n",
    "[58, 20404],\n",
    "[57, 86203],\n",
    "[59, 20645],\n",
    "[57, 19400],\n",
    "[60, 26310]]\n",
    "input_values = testx\n",
    "testx = process_array_for_prediction(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict(testx)\n",
    "prediction = asarray(prediction).ravel().reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = scaler.inverse_transform(prediction)\n",
    "prediction = prediction.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INPUT_VALUES:\")\n",
    "print(input_values)\n",
    "print(\"PREDICTION:\")\n",
    "print(prediction[0])\n",
    "print(\"Note:\", prediction[0][0], \"Length:\", prediction[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(101):\n",
    "    print_in_place(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.generate_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(x +2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
