{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Activation, Input, LSTM, Dense, Dropout, BatchNormalization, GRU, Flatten, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from pandas import read_csv\n",
    "from socketIO_client import SocketIO, LoggingNamespace\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# socket = SocketIO('localhost', 9876, LoggingNamespace)\n",
    "# from MidiPlayer import MidiPlayer\n",
    "# player = MidiPlayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout = 0.02\n",
    "n_time_steps = 50\n",
    "semi_redundancy_step = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', ' 0.9', ' 46']\n",
      "corpus length: 32\n"
     ]
    }
   ],
   "source": [
    "corpus = read_csv('Audio/data/output.csv', header=1)\n",
    "print(list(corpus))\n",
    "print('corpus length:', len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes_index = corpus.values[:, 0]\n",
    "length_index = corpus.values[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3164557 ]\n",
      " [0.03544304]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(length_index[:].reshape(-1,1))\n",
    "length_index = scaler.transform(length_index[:].reshape(-1,1))\n",
    "print(length_index[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_events: 128\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]\n"
     ]
    }
   ],
   "source": [
    "notes = sorted(list(set(notes_index)))\n",
    "notes = []\n",
    "for i in range(0, 128):\n",
    "    notes.append(i)\n",
    "    \n",
    "print('num_events:', len(notes))\n",
    "print(notes)\n",
    "note_index = dict((c, i) for i, c in enumerate(notes))\n",
    "index_note = dict((i, c) for i, c in enumerate(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 0\n",
      "______________\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9aa393cf3b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'______________'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'note_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote_phrases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'note_y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_note\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_phrases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "length_phrases = []\n",
    "next_length = []\n",
    "note_phrases = []\n",
    "next_note = []\n",
    "for i in range(0, len(notes_index) - n_time_steps, semi_redundancy_step):\n",
    "    note_phrases.append(notes_index[i: i + n_time_steps])\n",
    "    length_phrases.append(length_index[i: i + n_time_steps])\n",
    "    \n",
    "    next_note.append(notes_index[i + n_time_steps])\n",
    "    next_length.append(length_index[i + n_time_steps])\n",
    "print('nb sequences:', len(note_phrases))\n",
    "for i in range(2):\n",
    "    print('______________')\n",
    "    print('note_x', note_phrases[i])\n",
    "    print('note_y', next_note[i])\n",
    "    print('length_x', length_phrases[i])\n",
    "    print('length_y', next_length[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cd4343aaa7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# print('______________')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# print('length_y', length_y[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# print('note_x', note_x[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "\n",
    "note_x = np.zeros((len(note_phrases), n_time_steps, len(notes)), dtype=np.bool)\n",
    "note_y = np.zeros((len(note_phrases), len(notes)), dtype=np.bool)\n",
    "\n",
    "length_x = np.zeros((len(length_phrases), n_time_steps, 1))\n",
    "length_y = np.zeros((len(length_phrases), 1))\n",
    "\n",
    "for i, phrase in enumerate(note_phrases):\n",
    "    for t, note in enumerate(phrase):\n",
    "        note_x[i, t, note_index[note]] = 1\n",
    "    note_y[i, note_index[next_note[i]]] = 1\n",
    "\n",
    "for i, phrase in enumerate(length_phrases):\n",
    "    for t, length in enumerate(phrase):\n",
    "        length_x[i, t, 0] = length\n",
    "    length_y[i, 0] = next_length[i]\n",
    "    \n",
    "# print('______________')\n",
    "print('length_x', length_x[0])\n",
    "# print('length_y', length_y[0])\n",
    "# print('note_x', note_x[0])\n",
    "# print('note_y', note_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(note_x.shape)\n",
    "print(length_x.shape)\n",
    "print(note_y.shape)\n",
    "print(length_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 64\n",
    "\n",
    "note_input = Input(name='note_input', shape=(n_time_steps, len(notes)))\n",
    "length_input = Input(name='length_input', shape=(n_time_steps, 1))\n",
    "\n",
    "# input_merge = concatenate([note_input, length_input])\n",
    "\n",
    "# nn = LSTM(lstm_size, return_sequences=True)(input_merge)\n",
    "# # nn = Dropout(dropout)(nn)\n",
    "# nn = LSTM(lstm_size, return_sequences=True)(nn)\n",
    "\n",
    "note_branch = LSTM(lstm_size, return_sequences=True)(note_input)\n",
    "note_share = LSTM(int(lstm_size/4), return_sequences=True)(note_branch)\n",
    "\n",
    "length_branch = LSTM(lstm_size, return_sequences=True)(length_input)\n",
    "length_share = LSTM(int(lstm_size/4), return_sequences=True)(length_branch)\n",
    "\n",
    "length_merge = concatenate([length_branch, note_share])\n",
    "note_merge = concatenate([note_branch, length_share])\n",
    "\n",
    "length_lstm = LSTM(lstm_size, return_sequences=False)(length_merge)\n",
    "note_lstm = LSTM(lstm_size, return_sequences=False)(note_merge)\n",
    "                    \n",
    "output_notes = Dense(len(notes), activation='softmax', name='note_output')(note_lstm)\n",
    "length_output = Dense(1, activation='sigmoid', name='length_output')(length_lstm)\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.00001)\n",
    "model = Model(inputs=[note_input, length_input], outputs=[output_notes, length_output])\n",
    "model.compile(loss=['categorical_crossentropy', 'mean_squared_error'], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def midi_to_hertz(midi):\n",
    "    if midi == 0:\n",
    "        return 0\n",
    "    g = 2**(1/12)\n",
    "    return 440*g**(midi-69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    if epoch > 500 and epocch % 100 == 0:\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = 0\n",
    "#         random.randint(0, len(notes_index) - n_time_steps - 1)\n",
    "        for diversity in [1]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated_notes = []\n",
    "            generated_length = []\n",
    "            current_note_phrase = notes_index[start_index: start_index + n_time_steps]\n",
    "            current_length_phrase = length_index[start_index: start_index + n_time_steps]\n",
    "            generated_notes.extend(current_note_phrase)\n",
    "            generated_length.extend(current_length_phrase)\n",
    "    \n",
    "#             print('----- Generating with seed: ')\n",
    "#             print(current_note_phrase)\n",
    "#             print(generated_length)\n",
    "\n",
    "            n_generated = 50\n",
    "            start_time = time.time()\n",
    "            for i in range(n_generated):\n",
    "                x_pred = np.zeros((1, n_time_steps, len(notes)))\n",
    "                length_x_pred = np.zeros((1, n_time_steps, 1))\n",
    "\n",
    "                for t, event in enumerate(current_note_phrase):\n",
    "                    x_pred[0, t, note_index[event]] = 1.\n",
    "\n",
    "                for t, event in enumerate(current_length_phrase):\n",
    "                    length_x_pred[0, t, 0] = event\n",
    "\n",
    "                pred = model.predict([x_pred, length_x_pred], verbose=0)\n",
    "                note_pred = pred[0][0]\n",
    "                length_pred = pred[1]\n",
    "                \n",
    "                length_prediction = scaler.inverse_transform(length_pred)[0]\n",
    "                note_index_from_sample = sample(note_pred, diversity)\n",
    "                note_prediction = index_note[note_index_from_sample]\n",
    "                \n",
    "#                 print(note_prediction)\n",
    "#                 print(length_prediction)\n",
    "                \n",
    "                generated_notes.append(note_prediction)\n",
    "                generated_length.append(length_prediction)\n",
    "                \n",
    "                current_note_phrase = np.append(current_note_phrase[1:], note_prediction)\n",
    "                current_length_phrase = np.append(current_length_phrase[1:], length_pred)\n",
    "                \n",
    "                end_time = time.time()\n",
    "#             print(generated_notes)\n",
    "            \n",
    "#             print('average_prediction_speed:', (end_time-start_time)/n_generated)\n",
    "            generated_length_scaled = list(scaler.inverse_transform(generated_length).reshape(1,-1)[0])\n",
    "            counter = 0\n",
    "            for i in range(len(generated_notes)):\n",
    "                note = generated_notes[i]\n",
    "                length = generated_length_scaled[i]\n",
    "                freq = midi_to_hertz(note)\n",
    "                print(freq, '|', length)\n",
    "                if i == n_time_steps:\n",
    "                    print('generated')\n",
    "                    socket.emit('freq_change', {'freq': 4000, 'vol': 100})\n",
    "                    time.sleep(0.03)\n",
    "                \n",
    "                socket.emit('freq_change', {'freq': freq, 'vol': 100})\n",
    "                time.sleep(length * .5)\n",
    "\n",
    "\n",
    "            socket.emit('freq_change', {'freq': 0, 'vol': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit([note_x, length_x], [note_y, length_y],\n",
    "          batch_size=256,\n",
    "          epochs=1000,\n",
    "          callbacks=[print_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print('Saved scaler to disk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
