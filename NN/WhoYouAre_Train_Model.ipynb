{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "from numpy import concatenate, array, asarray\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.core import Activation\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import plot_model\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 128\n",
    "n_features = 2\n",
    "n_train_hours = 200\n",
    "n_divisions = 4\n",
    "batch_size = n_hours\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'num': 0}\n",
    "setattr(K, 'params', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "branch_input_size = int(n_hours)\n",
    "branch_output_size = int(n_hours/n_divisions/n_divisions)\n",
    "print(branch_input_size)\n",
    "print(branch_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitter(x):\n",
    "    num = K.params['num']\n",
    "    steps = int(n_hours/n_divisions)\n",
    "    start = int(num * steps)\n",
    "    end = int((num+1) * steps)\n",
    "    x = x[:,start:end]\n",
    "    print(start,end)\n",
    "    return x\n",
    "\n",
    "def split_shape(input_shape):\n",
    "    return (input_shape[0], int(input_shape[1]/n_divisions), input_shape[2])\n",
    "\n",
    "def timeseries_model(num_steps, num_features):\n",
    "    visible = Input(name='input', shape=(num_steps, num_features))\n",
    "    print(visible)\n",
    "    for i in range(0, n_divisions):\n",
    "        params = {'num': i}\n",
    "        setattr(K, 'params', params)\n",
    "        vars()[\"lambda\"+str(i)] = keras.layers.Lambda(splitter,\n",
    "                         output_shape=split_shape)(visible)\n",
    "        vars()[\"hidden\"+str(i)] = LSTM(branch_input_size, return_sequences=True)(vars()[\"lambda\"+str(i)])\n",
    "\n",
    "        vars()[\"batchNorm\"+str(i)] = BatchNormalization()(vars()[\"hidden\"+str(i)])\n",
    "\n",
    "        vars()[\"dropout\"+str(i)] = Dropout(0.5)(vars()[\"batchNorm\"+str(i)])\n",
    "\n",
    "        vars()[\"output\"+str(i)] = LSTM(branch_output_size, return_sequences=True)(vars()[\"dropout\"+str(i)])\n",
    "        print(vars()[\"output\"+str(i)])\n",
    "        \n",
    "    concat = keras.layers.concatenate([output0, output1, output2, output3])\n",
    "    print(concat)\n",
    "    tdd = keras.layers.TimeDistributed(Dense(branch_input_size))(concat)\n",
    "    hidden_Z = LSTM(branch_input_size)(tdd)\n",
    "\n",
    "    output_notes = Dense(1, activation='sigmoid', name='output_notes')(hidden_Z)\n",
    "    output_volume = Dense(1, activation='sigmoid', name='output_volume')(hidden_Z)\n",
    "\n",
    "    model = Model(inputs=[visible], outputs=[\n",
    "                                             output_notes, \n",
    "                                             output_volume, \n",
    "                                            ])\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='mae', optimizer=optimizer)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "plot_model(model, to_file='model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = [[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[ 0,  0],\n",
    "[84,  1],\n",
    "[84,  0],\n",
    "[86, 20],\n",
    "[89, 48],\n",
    "[89,  0],\n",
    "[90, 41],\n",
    "[91, 50],\n",
    "[91,  0],\n",
    "[92, 65],\n",
    "[92, 72],\n",
    "[92, 72],\n",
    "[92, 69],\n",
    "[80, 69],\n",
    "[80, 66],\n",
    "[80, 66],\n",
    "[92, 60],\n",
    "[92, 64],\n",
    "[92, 52],\n",
    "[92, 52],\n",
    "[92, 56],\n",
    "[92, 59],\n",
    "[92, 59],\n",
    "[92, 59],\n",
    "[92, 60],\n",
    "[92, 60],\n",
    "[93, 61],\n",
    "[93, 57],\n",
    "[93, 57],\n",
    "[93, 57],\n",
    "[92, 59],\n",
    "[92,  0],\n",
    "[92, 70],\n",
    "[92, 71],\n",
    "[92, 72],\n",
    "[92, 72],\n",
    "[92, 72],\n",
    "[92, 73],\n",
    "[92, 73],\n",
    "[92, 73],\n",
    "[92, 73],\n",
    "[92, 73],\n",
    "[92, 74],\n",
    "[92, 74],\n",
    "[92, 74],\n",
    "[92, 74],\n",
    "[92, 73],\n",
    "[93, 73],\n",
    "[93,  0],\n",
    "[93, 58],\n",
    "[92, 60],\n",
    "[92,  0],\n",
    "[92, 67],\n",
    "[92, 70],\n",
    "[92, 70],\n",
    "[92, 69],\n",
    "[92, 71],\n",
    "[92, 71],\n",
    "[92, 73],\n",
    "[91, 75],\n",
    "[91,  0],\n",
    "[90, 91],\n",
    "[89, 90],\n",
    "[89, 87],\n",
    "[89, 87],\n",
    "[90, 91],\n",
    "[90, 91],\n",
    "[90, 91],\n",
    "[90, 88],\n",
    "[90, 89],\n",
    "[90, 89],\n",
    "[90, 91],\n",
    "[90, 91],\n",
    "[90, 91],\n",
    "[90, 91],\n",
    "[90, 90],\n",
    "[90, 89],\n",
    "[90, 89],\n",
    "[90, 89],\n",
    "[90, 89],\n",
    "[78, 89],\n",
    "[78,  0],\n",
    "[90, 82],\n",
    "[90, 94],\n",
    "[90, 94],\n",
    "[78, 93],\n",
    "[90, 90],\n",
    "[90,  0],\n",
    "[78, 82],\n",
    "[90, 85],\n",
    "[90, 85],\n",
    "[90, 85],\n",
    "[90, 82],\n",
    "[90, 81],\n",
    "[90, 81],\n",
    "[90, 81],\n",
    "[90, 82],\n",
    "[90, 82],\n",
    "[90, 82],\n",
    "[90, 82],\n",
    "[90, 80],\n",
    "[90, 80],\n",
    "[90, 79],\n",
    "[90, 79],\n",
    "[90, 80],\n",
    "[90, 80],\n",
    "[90, 80],\n",
    "[90, 81],\n",
    "[90, 81],\n",
    "[90, 81],\n",
    "[90, 81],\n",
    "[90, 81],\n",
    "[90, 81],\n",
    "[90, 81]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = DataFrame(data = test_data)\n",
    "testx = testx.values\n",
    "testx = testx.astype('float32')\n",
    "testx = scaler.transform(testx)\n",
    "testx = series_to_supervised(testx, n_hours, 1)\n",
    "print(testx)\n",
    "testx = testx.values\n",
    "testx = testx[:, :n_obs]\n",
    "testx = testx.reshape((testx.shape[0], n_hours, n_features))\n",
    "print(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    print()\n",
    "    print('----- Generating sound after: %d' % epoch)\n",
    "\n",
    "    \n",
    "    print('input_values:', input_values[20:30])\n",
    "    prediction = model.predict(test)\n",
    "    print(prediction)\n",
    "#     prediction = asarray(prediction).ravel().reshape(-1,2)\n",
    "#     prediction = scaler.inverse_transform(prediction)\n",
    "#     prediction = prediction.astype('int')\n",
    "# #     print(\"INPUT_VALUES:\")\n",
    "# #     print(input_values)\n",
    "#     print(\"PREDICTION:\")\n",
    "#     print(prediction[0])\n",
    "#     print(\"Note:\", prediction[0][0], \"Volume:\", prediction[0][1])\n",
    "    \n",
    "play_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "            {'input': train_X},\n",
    "            {\n",
    "                'output_notes': train_y_notes, \n",
    "                'output_volume': train_y_volume, \n",
    "#                 'output_length': train_y_length\n",
    "            },\n",
    "            validation_data=({'input': test_X},\n",
    "                             {\n",
    "                                 'output_notes': test_y_notes, \n",
    "                                 'output_volume': test_y_volume, \n",
    "#                                  'output_length': test_y_length\n",
    "                             }), \n",
    "            verbose=1,\n",
    "            shuffle=False,\n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[play_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
