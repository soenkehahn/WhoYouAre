{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from collections import deque\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from numpy import concatenate, array, asarray\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Input\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert series to supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ingest_csv(fileName):\n",
    "    dataset = read_csv(fileName, header=0)\n",
    "    values = dataset.values\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float32')\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and Scale the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 10\n",
    "n_features = 2\n",
    "n_obs = n_hours * n_features\n",
    "\n",
    "values = ingest_csv('music_data.csv')\n",
    "\n",
    "# normalize features\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    var1(t-10)  var2(t-10)  var1(t-9)  var2(t-9)  var1(t-8)  var2(t-8)  \\\n",
      "10         0.6     0.05137       0.59   0.027755       0.62   0.052183   \n",
      "\n",
      "    var1(t-7)  var2(t-7)  var1(t-6)  var2(t-6)    ...     var1(t-4)  \\\n",
      "10        0.6   0.042226       0.59   0.041762    ...          0.58   \n",
      "\n",
      "    var2(t-4)  var1(t-3)  var2(t-3)  var1(t-2)  var2(t-2)  var1(t-1)  \\\n",
      "10   0.040089       0.57   0.187012       0.59   0.040628       0.57   \n",
      "\n",
      "    var2(t-1)  var1(t)   var2(t)  \n",
      "10   0.037848      0.6  0.053277  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)\n",
    "print(reframed[0:1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = reframed.values\n",
    "n_train_steps = 9000\n",
    "train = values[:n_train_steps, :]\n",
    "test = values[n_train_steps:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 10, 2) (9000,) (3236, 10, 2) (3236,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y_notes = train[:, :n_obs], train[:, -n_features]\n",
    "train_y_length = train[:, -n_features -1]\n",
    "\n",
    "test_X, test_y_notes = test[:, :n_obs], test[:, -n_features]\n",
    "test_y_length = test[:, -n_features -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y_notes.shape, test_X.shape, test_y_notes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_main (InputLayer)          (None, 10, 2)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 10, 10)        520         input_main[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 10, 10)        40          lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 10, 10)        0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 10, 10)        840         dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 10, 10)        40          lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 10, 10)        0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 10, 10)        840         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 10, 10)        40          lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 10, 10)        0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 10)            840         dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "output_notes (Dense)             (None, 1)             11          lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "output_length (Dense)            (None, 1)             11          lstm_4[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 3,182\n",
      "Trainable params: 3,122\n",
      "Non-trainable params: 60\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_array_for_prediction(testx):\n",
    "    testx = DataFrame(data = testx)\n",
    "    testx = testx.values\n",
    "    testx = testx.astype('float32')\n",
    "    testx = scaler.transform(testx)\n",
    "    testx = series_to_supervised(testx, n_hours, 1)\n",
    "    testx = testx.values\n",
    "    testx = testx[:, :n_obs]\n",
    "    testx = testx.reshape((testx.shape[0], n_hours, n_features))\n",
    "    return testx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "\n",
    "testx = [[60, 25456],\n",
    "[59, 14880],\n",
    "[62, 25820],\n",
    "[60, 21361],\n",
    "[59, 21153],\n",
    "[60, 26320],\n",
    "[58, 20404],\n",
    "[57, 86203],\n",
    "[59, 20645],\n",
    "[57, 19400],\n",
    "[60, 26310]]\n",
    "\n",
    "input_values = testx\n",
    "\n",
    "testx = process_array_for_prediction(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64459348  0.08480092]]\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict(testx)\n",
    "prediction = asarray(prediction).ravel().reshape(-1,2)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = scaler.inverse_transform(prediction)\n",
    "prediction = prediction.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_VALUES:\n",
      "[[60, 25456], [59, 14880], [62, 25820], [60, 21361], [59, 21153], [60, 26320], [58, 20404], [57, 86203], [59, 20645], [57, 19400], [60, 26310]]\n",
      "PREDICTION:\n",
      "[   64 40428]\n",
      "Note: 64 Length: 40428\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT_VALUES:\")\n",
    "print(input_values)\n",
    "print(\"PREDICTION:\")\n",
    "print(prediction[0])\n",
    "print(\"Note:\", prediction[0][0], \"Length:\", prediction[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
